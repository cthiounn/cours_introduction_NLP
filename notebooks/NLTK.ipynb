{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdd73b8a-a220-4290-8ae7-a45113b72674",
   "metadata": {},
   "source": [
    "## Séance 1 - Caractérisation du texte : approche fréquentiste - Préparer le texte et compter les mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb0492-5b0a-4a17-ab1f-70f34d5f29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q nltk seaborn pandas WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48396218-8baf-415d-b02b-6050c205c85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT=\"\"\"   \n",
    "ACCORD D’ENTREPRISE \n",
    "Prime Jeux Olympiques et Paralympiques\n",
    "AIRLINES GROUND SERVICES\n",
    "Du 11 juillet 2024 \n",
    "\n",
    "\n",
    "Entre les soussignés :\n",
    "\n",
    "La société AIRLINES GROUND SERVICES au capital de 38 112 €, inscrite au registre du commerce et des sociétés de Bobigny sous le numéro 411 545 080, dont le siège social est situé à Tremblay en France (Seine Saint Denis) au 3 rue du Remblai, représentée par Xxx, agissant en qualité de Président, \n",
    "\n",
    "Ci-après dénommée la « Société »\n",
    "\n",
    "D’UNE PART \n",
    "\n",
    "ET \n",
    "\n",
    "Les organisations syndicales représentées par : \n",
    "\n",
    "Xxx pour la CGT, délégué syndical,\n",
    "Xxx pour le SMA, délégué syndical,\n",
    "Xxx pour la CFTC, délégué syndical,\n",
    "Xxx pour la CFE-CGC, délégué syndical\n",
    "Xxx pour FO, délégué syndical\n",
    "\n",
    "Ci-après dénommées les « Organisations Syndicales »\t\n",
    "\n",
    "D’AUTRE PART\n",
    "\n",
    "Ci-après dénommées ensemble « les Parties »\n",
    "\n",
    "Afin de répondre aux revendications salariales du personnel de la société AIRLINES GROUND SERVICES et dans le cadre de l’évènement des Jeux Olympiques et Paralympiques organisés en France et le travail des salariés pendant cette période, il a été convenu et arrêté les points suivants : \n",
    "\n",
    "\n",
    "Article 1 – Champ d’application\n",
    "\n",
    "Le présent accord s’applique à l’ensemble du personnel salarié de la société AIRLINES GROUND SERVICES.\n",
    "\n",
    "Article 2 – Portée de l’accord\n",
    "\n",
    "Le présent accord est conclu dans le cadre des textes en vigueur du Code du travail. \n",
    "Cet accord mettant en place des dispositions plus favorables que celles prévues actuellement par la Convention Collective Transport Aérien Personnel au Sol n° 3177, il s’y substitue en ce qui concerne la grille des minimas hiérarchiques.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec9fa3-8dc4-4a06-a6b4-803311f8a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae53cab-e3b2-4e37-b7a0-7ab25d84fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module pour les ponctuations, pour savoir comment découper \"M. XXX a trois chats. Il a également deux chiens.\" => [\"M.\", \"XXX\", ...]\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae87f4-4ccc-4867-a4f2-f16ea75df6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module pour les stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31693f47-21ba-433e-bb3d-f45d660def2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module pour lemmatiser\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea01248-87ff-43d2-a95a-6d7aa092ad2c",
   "metadata": {},
   "source": [
    "### Tokeniser en phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b4e8b3-b81f-4031-a2c7-e0c570208231",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5363c039-e4f0-4d9e-995e-6f5a36c6c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(TEXT,language=\"french\")\n",
    "for i,phrase in enumerate(sentences):\n",
    "    print(phrase)\n",
    "    print(\"-\"*10)\n",
    "    if i == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c501e776-0b62-4b56-8fab-a0c36bd12e93",
   "metadata": {},
   "source": [
    "### Tokeniser en mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da629a6-a880-4644-a27f-9778e2deeb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(TEXT)\n",
    "for i,mots in enumerate(words):\n",
    "    print(mots)\n",
    "    print(\"-\"*10)\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdad448-57b9-4aa4-ab1b-6950ab26d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(TEXT, language='french')\n",
    "for i,mots in enumerate(words):\n",
    "    print(mots)\n",
    "    print(\"-\"*10)\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f54b7c-6738-4945-a884-433a0c42b883",
   "metadata": {},
   "source": [
    "### Stopwords et ponctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dabac9-e89e-40e9-a543-b5c2b98a734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a1a14-1493-4174-bd7b-8599e6c33338",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a84d9-b6da-4c75-a3f7-2bc8e354f54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1945f5cd-c5ae-43e5-a6a3-36cec3b6f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_lowers=[w.lower() for w in words]\n",
    "words_without_stopw_punc=[w for w in words_lowers if w not in stop_words and w not in string.punctuation]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d726394b-eebe-4420-bfd7-e33bc642c9c4",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54fc76-7be1-49a9-bf04-89f2aeda38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ffe790-f329-40ea-bc8a-0881b7edca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer.stem(\"mangées\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e350df-a655-4815-9452-019a586abee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer.stem(\"mangeraient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec65c0-cce3-473c-8ea0-235cf9184ac5",
   "metadata": {},
   "source": [
    "### Lemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effcebab-95c6-4744-bbbd-c92228973741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "print(wnl.lemmatize('dispositions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd80f83-1071-4727-b238-9b48e74887dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wnl.lemmatize('manger'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f3860-9d13-4ab7-8b00-c5394e55696c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wnl.lemmatize('disposait'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b1d89d-7294-4fe4-8cb2-363bf7881803",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wnl.lemmatize('dispositifs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d823066b-d0a5-4603-ae14-f52ee8b29098",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wnl.lemmatize('dispositif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897f24bd-627c-4fbb-8010-74dccf40674c",
   "metadata": {},
   "source": [
    "### Compter les mots (tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0886577-d41a-4261-923b-3b6fc91c8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(words)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9a15d0-0c0c-4dba-bfca-65952476028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(words_without_stopw_punc)\n",
    "fdist\n",
    "fdist.plot(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d6c284-76e7-4abb-b625-d53d6b89a0e0",
   "metadata": {},
   "source": [
    "### Visualiser le texte - nuage de mots (WordCloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46db39-29b3-42e1-a987-c447260a1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot  as plt\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(\" \".join(words))  # Créer le nuage de mots\n",
    "\n",
    "# Afficher le nuage de mots\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5105bf9-2673-4732-a853-bce60c402939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot  as plt\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(\" \".join(words_without_stopw_punc))  # Créer le nuage de mots\n",
    "\n",
    "# Afficher le nuage de mots\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6804b209-e42d-4dca-801b-7dd063590d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "words_without_stop_words_and_punctuation=[w for w in words_without_stopw_punc if  w!=\"’\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6a440-4879-45f5-b3af-31e1f249ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(words_without_stop_words_and_punctuation)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c45bdb-46bf-457d-929c-e20b296cc98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ef5d6-4ffa-4f06-95ae-2450ee909cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot  as plt\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(\" \".join(words_without_stop_words_and_punctuation))  # Créer le nuage de mots\n",
    "\n",
    "# Afficher le nuage de mots\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12df3ead-49c9-450a-ac93-9d42819a95bf",
   "metadata": {},
   "source": [
    "## Séance 2 - Caractérisation du texte - Compter les mots par ensemble - Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac95ece-1cf3-483f-b311-ec54cd6c4c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "tokens = words_without_stop_words_and_punctuation\n",
    "# Generate bigrams (2-grams)\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "\n",
    "# Print the bigrams\n",
    "print(tokens)\n",
    "print(bigrams)\n",
    "\n",
    "# You can also generate trigrams or higher n-grams\n",
    "trigrams = list(ngrams(tokens, 3))\n",
    "print(trigrams)\n",
    "\n",
    "# For any n-gram, simply change the second parameter of the ngrams function\n",
    "n = 4  # Example for 4-grams\n",
    "fourgrams = list(ngrams(tokens, n))\n",
    "print(fourgrams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0090a69-fef5-42ee-8df7-49ce16fc1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Create bigrams\n",
    "bigrams = list(ngrams(tokens, 2))\n",
    "\n",
    "# Count the frequency of bigrams\n",
    "fdist = FreqDist(bigrams)\n",
    "\n",
    "# Print the most common bigrams\n",
    "print(fdist.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982f41cb-04b1-466d-b36e-613a50e70be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Convert the frequency distribution to a pandas DataFrame\n",
    "bigram_freq_df = pd.DataFrame(fdist.items(), columns=['Bigram', 'Frequency'])\n",
    "\n",
    "# Split the bigram tuples into separate columns for better handling\n",
    "bigram_freq_df[['Word1', 'Word2']] = pd.DataFrame(bigram_freq_df['Bigram'].tolist(), index=bigram_freq_df.index)\n",
    "\n",
    "# Remove the original 'Bigram' column as we no longer need it\n",
    "bigram_freq_df.drop(columns=['Bigram'], inplace=True)\n",
    "\n",
    "# Sort by frequency to get the most common bigrams\n",
    "bigram_freq_df = bigram_freq_df.sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "# Create a new column for better labeling in the plot (e.g., 'Word1 Word2')\n",
    "bigram_freq_df['Bigram'] = bigram_freq_df['Word1'] + ' ' + bigram_freq_df['Word2']\n",
    "\n",
    "# Plot the top 10 bigrams using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Frequency', y='Bigram', data=bigram_freq_df.head(10), hue='Bigram', palette='viridis', dodge=False, legend=False)\n",
    "plt.title('Top 10 Bigrams by Frequency')\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('Bigrams')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7276eb6b-0a4b-4b2b-939e-19b688d9ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Create bigrams\n",
    "bigrams = list(ngrams(tokens, 3))\n",
    "\n",
    "# Count the frequency of bigrams\n",
    "fdist = FreqDist(bigrams)\n",
    "\n",
    "# Print the most common bigrams\n",
    "print(fdist.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a466529a-1499-4716-bc76-1b3423a97675",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.plot(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcb9bd1-33bf-4697-b32c-8a98e7db75d7",
   "metadata": {},
   "source": [
    "## Séance 3 - Caractérisation du texte - Analyser les cooccurrences et les concordances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf070eab-7047-4b05-a9da-397d78a1a975",
   "metadata": {},
   "source": [
    "### Concordance : mots avant et après (contexte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda784d8-1548-4a2d-a06a-7b28acba30f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nltk = nltk.Text(words_without_stop_words_and_punctuation)\n",
    "\n",
    "text_nltk.concordance('paralympiques')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4aa204-b9db-47f6-bcd7-1a8c48b9e6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nltk.concordance('jeux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66b70ba-ec98-475d-9d6f-f6788f8b1cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nltk.concordance('france')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1847b4d9-d90a-4387-b95e-2eb28add864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_nltk.concordance('salarié')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77f2c6d-df0b-4a73-a12c-e9919e7ee2b4",
   "metadata": {},
   "source": [
    "### Co-occurences : Mots qui apparaissent ensemble dans les phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a6340-e657-4061-a975-0e7993d07212",
   "metadata": {},
   "source": [
    "* pas de fonction dans NTLK pour faire cela, hormis les n-grams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
